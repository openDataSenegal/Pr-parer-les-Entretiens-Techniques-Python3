{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIBLIOTEQUES ET LIBRAIRIES NECESSAIRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains some Hackerrank problems that I solved for fun. I hope this will help you prepare for your interview. The solution is not optimized):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Army Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/armyGame1.png\" alt=\"Problem_1\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/armyGame0.png\" alt=\"Problem_0\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Complete the 'gameWithCells' function below.\n",
    "#\n",
    "# The function is expected to return an INTEGER.\n",
    "# The function accepts following parameters:\n",
    "#  1. INTEGER n\n",
    "#  2. INTEGER m\n",
    "#\n",
    "def gameWithCells(n, m):\n",
    "    \"\"\"\n",
    "        Solution\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    if((n%2 == 1) and (m%2 == 1) and (n>1) and (m>1)):\n",
    "        return int(((n-1)*(m-1))/4)+int(m/2)+(m%2)+int(n/2)\n",
    "    if((n == 1) and (m%2 == 1) and(m>1)):\n",
    "        return int(m/2)+1\n",
    "    if((m == 1) and (n%2 == 1) and(n>1)):\n",
    "        return int(n/2)+1\n",
    "    if(n%2 == 1):\n",
    "        return int(((n-1)*m)/4)+int(m/2)+(m%2)\n",
    "    if(m%2 == 1):\n",
    "        return int((n*(m-1))/4)+int(n/2)+(n%2)\n",
    "    return max(int((n*m)/4),1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fptr = open(os.environ['OUTPUT_PATH'], 'w')\n",
    "\n",
    "    first_multiple_input = input().rstrip().split()\n",
    "\n",
    "    n = int(first_multiple_input[0])\n",
    "\n",
    "    m = int(first_multiple_input[1])\n",
    "\n",
    "    result = gameWithCells(n, m)\n",
    "\n",
    "    fptr.write(str(result) + '\\n')\n",
    "\n",
    "    fptr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fizz Buzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/fizzBuzz0.png\" alt=\"Problem_1\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/fizzBuzz1.png\" alt=\"Problem_0\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/twins0.png\" alt=\"Problem_0\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#\n",
    "# Complete the 'solve' function below.\n",
    "#\n",
    "# The function is expected to return an INTEGER.\n",
    "# The function accepts following parameters:\n",
    "#  1. INTEGER n\n",
    "#  2. INTEGER m\n",
    "#\n",
    "\n",
    "    \n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n > 2 and n % 2 == 0:\n",
    "        return False\n",
    " \n",
    "    max_div = math.floor(math.sqrt(n))\n",
    "    for i in range(3, 1 + max_div, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "    \n",
    "def SieveOfEratosthenes(minimum_primary, n):\n",
    "    prime = [True for i in range(n+1)]\n",
    "    list_primafry_number = []\n",
    "    p = 2\n",
    "    while(p * p <= n):\n",
    "        if (prime[p] == True):\n",
    "            for i in range(p * p, n + 1, p):\n",
    "                prime[i] = False\n",
    "        p += 1\n",
    " \n",
    "    for p in range(max(minimum_primary,2), n):\n",
    "        if prime[p]:\n",
    "            list_primafry_number.append(p)\n",
    "    return list_primafry_number\n",
    "\n",
    "    \n",
    "    \n",
    "def solve(n, m):\n",
    "    # Write your code here\n",
    "    number_of_tiws = 0\n",
    "    list_values_all = SieveOfEratosthenes(max(n,2), m+1) # sorted(list_values_all)\n",
    "\n",
    "    for first_value in list_values_all:\n",
    "        if(first_value+2 in list_values_all):\n",
    "            number_of_tiws+=1\n",
    "    return number_of_tiws\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fptr = open(os.environ['OUTPUT_PATH'], 'w')\n",
    "\n",
    "    first_multiple_input = input().rstrip().split()\n",
    "\n",
    "    n = int(first_multiple_input[0])\n",
    "\n",
    "    m = int(first_multiple_input[1])\n",
    "\n",
    "    result = solve(n, m)\n",
    "\n",
    "    fptr.write(str(result) + '\\n')\n",
    "\n",
    "    fptr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Regression Lines - A Quick Recap #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/CorrelationAndRegressionLines.png\" alt=\"Correlation And Regression Lines\" style=\"height: 700px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def mean_list(list_to_mean):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return sum(list_to_mean)/len(list_to_mean)\n",
    "\n",
    "\n",
    "def different_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]-second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "def product_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]*second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "\n",
    "def karl_pearson_correlation(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "        uses this function to comput Karl Pearson Correlation\n",
    "    \"\"\"\n",
    "\n",
    "    tamp1 = sum(product_between_two_vector(different_between_two_vector(first_vector,len(first_vector)*[mean_list(first_vector)]), different_between_two_vector(second_vector,len(second_vector)*[mean_list(second_vector)])))\n",
    "    tampon_values_first = different_between_two_vector(first_vector,len(first_vector)*[mean_list(first_vector)])\n",
    "    tampon_values_second = different_between_two_vector(second_vector,len(second_vector)*[mean_list(second_vector)])\n",
    "    tamp2 = math.sqrt(sum(product_between_two_vector(tampon_values_first,tampon_values_first))*sum(product_between_two_vector(tampon_values_second,tampon_values_second)))\n",
    "    if (tamp2 == 0.0):\n",
    "        if (first_vector == second_vector):\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    return tamp1/tamp2\n",
    "\n",
    "first_vector = [15, 12, 8, 8, 7, 7, 7, 6, 5, 3]\n",
    "second_vector = [10, 25, 17, 11, 13, 17, 20, 13, 9, 15]\n",
    "print('%.3f' % round(karl_pearson_correlation(first_vector, second_vector),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6: Multiple Linear Regression: Predicting House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/Day6MultipleLinearRegressionPredictingHousePrices_0.png\" alt=\"Day 6: Multiple Linear Regression: Predicting House Prices 0\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/Day6MultipleLinearRegressionPredictingHousePrices_1.png\" alt=\"Day 6: Multiple Linear Regression: Predicting House Prices 1\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/Day6MultipleLinearRegressionPredictingHousePrices_2.png\" alt=\"Day 6: Multiple Linear Regression: Predicting House Prices 2\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Regression Lines - A Quick Recap #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/CorrelationRegressionLinesAQuickRecap.png\" alt=\"Correlation Regression Lines A Quick Recap\" style=\"height: 400px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "import math\n",
    "\n",
    "def mean_list(list_to_mean):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return sum(list_to_mean)/len(list_to_mean)\n",
    "\n",
    "def different_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]-second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "def product_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]*second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "    \n",
    "def compute_slope_regression(X, Y):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    #slope = 1\n",
    "    mean_x = mean_list(X)\n",
    "    mean_y = mean_list(Y)\n",
    "    return sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(Y, len(Y)*[mean_y])))/sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(X, len(X)*[mean_x])))    \n",
    "\n",
    "    \n",
    "physics_scores = [15, 12, 8, 8, 7, 7, 7, 6, 5, 3]\n",
    "history_scores = [10, 25, 17, 11, 13, 17, 20, 13, 9, 15]\n",
    "print('%.3f' % round(compute_slope_regression(physics_scores, history_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camel Case 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/CamelCase40.png\" alt=\"Camel Case 4 0\" style=\"height: 900px; width:1000px;\"/>\n",
    "<img src=\"./HackerRankFile/CamelCase41.png\" alt=\"Camel Case 4 1\" style=\"height: 400px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "import re\n",
    "import os\n",
    " \n",
    "\n",
    "\n",
    "def camel_case_four(input_string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    result_string = \"\"\n",
    "    split_input_result = input_string.split(\";\")\n",
    "    if(split_input_result[0] == \"S\"):\n",
    "        if(split_input_result[1] == \"C\"):\n",
    "            result_split_regex = re.findall('[A-Z][^A-Z]*', split_input_result[2])\n",
    "            #result_string = result_split_regex[0].lower()+\" \"+result_split_regex[1].lower()\n",
    "            result_string = result_split_regex[0].lower()\n",
    "            for one_result in range(1, len(result_split_regex)):\n",
    "                result_string += \" \"+result_split_regex[one_result].lower()\n",
    "        if(split_input_result[1] == \"M\"):\n",
    "            result_split_regex = re.split('(?=[A-Z])', split_input_result[2])\n",
    "            result_string = result_split_regex[0].lower()\n",
    "            for one_result in range(1, len(result_split_regex)):\n",
    "                result_string += \" \"+result_split_regex[one_result].lower()\n",
    "            result_string = result_string[:-2].lower()\n",
    "        if(split_input_result[1] == \"V\"):\n",
    "            result_split_regex = re.split('(?=[A-Z])', split_input_result[2])\n",
    "            result_string = result_split_regex[0].lower()\n",
    "            for one_result in range(1, len(result_split_regex)):\n",
    "                result_string += \" \"+result_split_regex[one_result].lower()\n",
    "            \n",
    "    if(split_input_result[0] == \"C\"):\n",
    "        result_split_regex = split_input_result[2].split(\" \")\n",
    "        if(split_input_result[1] == \"C\"):\n",
    "            for one_result in result_split_regex:\n",
    "                result_string += one_result[0].upper()+one_result[1:].lower()\n",
    "        if(split_input_result[1] == \"M\"):\n",
    "            result_string = result_split_regex[0].lower()\n",
    "            for one_result in range(1, len(result_split_regex)):\n",
    "                result_string += result_split_regex[one_result][0].upper()+result_split_regex[one_result][1:]\n",
    "            result_string +=\"()\"\n",
    "        if(split_input_result[1] == \"V\"):\n",
    "            result_string = result_split_regex[0].lower()\n",
    "            for one_result in range(1, len(result_split_regex)):\n",
    "                result_string += result_split_regex[one_result][0].upper()+result_split_regex[one_result][1:]\n",
    "    return result_string\n",
    "\n",
    "    \n",
    "fptr = open(os.environ['OUTPUT_PATH'], 'w')\n",
    "while True:\n",
    "    try:\n",
    "        first_multiple_input = input().rstrip().split()\n",
    "    except:\n",
    "        break\n",
    "    n = \" \".join(first_multiple_input)\n",
    "    result = camel_case_four(n)\n",
    "    fptr.write(str(result) + '\\n')\n",
    "fptr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisible Sum Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/DivisibleSumPairs0.png\" alt=\"Divisible Sum Pairs\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/DivisibleSumPairs1.png\" alt=\"Divisible Sum Pairs\" style=\"height: 400px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisibleSumPairs(n, k, ar):\n",
    "    # Write your code here\n",
    "    number_of_pair = 0\n",
    "    \n",
    "    for first_el in range(n-1):\n",
    "        for second_el in range(first_el+1, n):\n",
    "            if((ar[first_el]+ar[second_el])%k == 0):\n",
    "                number_of_pair+=1\n",
    "    return number_of_pair\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fptr = open(os.environ['OUTPUT_PATH'], 'w')\n",
    "\n",
    "    first_multiple_input = input().rstrip().split()\n",
    "\n",
    "    n = int(first_multiple_input[0])\n",
    "\n",
    "    k = int(first_multiple_input[1])\n",
    "\n",
    "    ar = list(map(int, input().rstrip().split()))\n",
    "\n",
    "    result = divisibleSumPairs(n, k, ar)\n",
    "\n",
    "    fptr.write(str(result) + '\\n')\n",
    "\n",
    "    fptr.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Regression Lines - A quick recap #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/CorrelationAndRegressionLinesAquickrecap30.png\" alt=\"Correlation and Regression Lines - A quick recap #3\" style=\"height: 400px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "import math\n",
    "\n",
    "def mean_list(list_to_mean):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return sum(list_to_mean)/len(list_to_mean)\n",
    "\n",
    "def different_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]-second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "def product_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]*second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "    \n",
    "def compute_coef_regression(X, Y):\n",
    "    \"\"\"\n",
    "        Y = A+BX\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_x = mean_list(X)\n",
    "    mean_y = mean_list(Y)\n",
    "    \n",
    "    cov_X_Y = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(Y, len(Y)*[mean_y])))\n",
    "    var_X = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(X, len(X)*[mean_x])))\n",
    "    \n",
    "    B = cov_X_Y/var_X\n",
    "    A = mean_y- B*mean_x\n",
    "    return A, B    \n",
    "\n",
    "\n",
    "physics_scores = [15, 12, 8, 8, 7, 7, 7, 6, 5, 3]\n",
    "history_scores = [10, 25, 17, 11, 13, 17, 20, 13, 9, 15]\n",
    "A, B = compute_coef_regression(physics_scores, history_scores)\n",
    "print('%.3f' % round(A+B*10,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Regression Lines - A Quick Recap #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/CorrelationandRegressionLinesAQuickRecap4_0.png\" alt=\"Correlation and Regression Lines - A Quick Recap #4\" style=\"height: 400px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "print(round((107+9*7)/20,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5: Computing the Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/Day5ComputingTheCorrelation0.png\" alt=\"Day 5: Computing the Correlation 0\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/Day5ComputingTheCorrelation1.png\" alt=\"Day 5: Computing the Correlation 1\" style=\"height: 900px; width:900px;\"/>\n",
    "<img src=\"./HackerRankFile/Day5ComputingTheCorrelation2.png\" alt=\"Day 5: Computing the Correlation 2\" style=\"height: 200px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "# Processing Data \n",
    "import os\n",
    "import math\n",
    "\n",
    "input_data_all = \"\"\"73  72  76\n",
    "48  67  76\n",
    "95  92  95\n",
    "95  95  96\n",
    "33  59  79\n",
    "47  58  74\n",
    "98  95  97\n",
    "91  94  97\n",
    "95  84  90\n",
    "93  83  90\n",
    "70  70  78\n",
    "85  79  91\n",
    "33  67  76\n",
    "47  73  90\n",
    "95  87  95\n",
    "84  86  95\n",
    "43  63  75\n",
    "95  92  100\n",
    "54  80  87\n",
    "72  76  90\"\"\"\n",
    "input_data_all = input_data_all.split(\"\\n\")\n",
    "\n",
    "M = []\n",
    "P = []\n",
    "C = []\n",
    "for one_element in input_data_all:\n",
    "    split_element = one_element.split(\" \")\n",
    "    M.append(int(split_element[0]))\n",
    "    P.append(int(split_element[2]))\n",
    "    C.append(int(split_element[4]))\n",
    "    \n",
    "\n",
    "def mean_list(list_to_mean):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return sum(list_to_mean)/len(list_to_mean)\n",
    "\n",
    "    \n",
    "def different_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]-second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "def product_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]*second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "    \n",
    "def compute_correlation(X, Y):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_x = mean_list(X)\n",
    "    mean_y = mean_list(Y)\n",
    "    \n",
    "    cov_X_Y = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(Y, len(Y)*[mean_y])))\n",
    "    var_X = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(X, len(X)*[mean_x])))\n",
    "    var_Y = sum(product_between_two_vector(different_between_two_vector(Y, len(Y)*[mean_y]), different_between_two_vector(Y, len(X)*[mean_y])))\n",
    "    return cov_X_Y/math.sqrt(var_X*var_Y)\n",
    "\n",
    "print('%.2f' % round(compute_correlation(M, P),2))\n",
    "print('%.2f' % round(compute_correlation(P, C),2))\n",
    "print('%.2f' % round(compute_correlation(M, C),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HackerRankFile/DocumentClassification0.png\" alt=\"Document Classification\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata_pandas = pd.read_csv(\"HackerRankFile/trainingdata.txt\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extract Labeland Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Containt</th>\n",
       "      <th>Label_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Document_Containt Label_Document\n",
       "0  champion products ch approves stock split cham...              1\n",
       "1  computer terminal systems cpml completes sale ...              2\n",
       "2  cobanco inc cbco year net shr cts vs dlrs net ...              1\n",
       "3  am international inc am nd qtr jan oper shr lo...              1\n",
       "4  brown forman inc bfd th qtr net shr one dlr vs...              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata_pandas['Document_Containt'] = trainingdata_pandas.apply(lambda row: row[\"5485\"][2:], axis = 1)\n",
    "trainingdata_pandas[\"Label_Document\"] = trainingdata_pandas.apply(lambda row: row[\"5485\"][0:1], axis = 1)\n",
    "del trainingdata_pandas[\"5485\"]\n",
    "trainingdata_pandas.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split Data Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(trainingdata_pandas[\"Document_Containt\"],\n",
    "                                                  trainingdata_pandas[\"Label_Document\"],\n",
    "                                                  test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Support Vector Classification OneVsRestClassifier Tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 1))),\n",
    "                       ('nb_model', OneVsRestClassifier(SVC()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you...\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('nb_model',\n",
       "                 OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False,\n",
       "                                                   cache_size=200,\n",
       "                                                   class_weight=None, coef0=0.0,\n",
       "                                                   decision_function_shape='ovr',\n",
       "                                                   degree=3, gamma='scale',\n",
       "                                                   kernel='rbf', max_iter=-1,\n",
       "                                                   probability=False,\n",
       "                                                   random_state=None,\n",
       "                                                   shrinking=True, tol=0.001,\n",
       "                                                   verbose=False),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipeline.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_prediction_result = svc_pipeline.predict(X_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9608021877848678\n",
      "f1 Score weighted :  0.9604545770912919\n",
      "f1 Score micro :  0.9608021877848678\n",
      "f1 Score macro :  0.9208470294427842\n",
      "confusion matrices: \n",
      "[[[ 535    6]\n",
      "  [  15  541]]\n",
      "\n",
      " [[ 747   27]\n",
      "  [   3  320]]\n",
      "\n",
      " [[1039    4]\n",
      "  [   1   53]]\n",
      "\n",
      " [[1077    0]\n",
      "  [   4   16]]\n",
      "\n",
      " [[1088    0]\n",
      "  [   2    7]]\n",
      "\n",
      " [[1044    0]\n",
      "  [   5   48]]\n",
      "\n",
      " [[1057    2]\n",
      "  [   5   33]]\n",
      "\n",
      " [[1049    4]\n",
      "  [   8   36]]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.97      0.98       556\n",
      "           2       0.92      0.99      0.96       323\n",
      "           3       0.93      0.98      0.95        54\n",
      "           4       1.00      0.80      0.89        20\n",
      "           5       1.00      0.78      0.88         9\n",
      "           6       1.00      0.91      0.95        53\n",
      "           7       0.94      0.87      0.90        38\n",
      "           8       0.90      0.82      0.86        44\n",
      "\n",
      "    accuracy                           0.96      1097\n",
      "   macro avg       0.96      0.89      0.92      1097\n",
      "weighted avg       0.96      0.96      0.96      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy_score(y_val.values, svc_prediction_result))\n",
    "print(\"f1 Score weighted : \",f1_score(y_val.values, svc_prediction_result, average='weighted'))\n",
    "print(\"f1 Score micro : \",f1_score(y_val.values, svc_prediction_result, average='micro'))\n",
    "print(\"f1 Score macro : \",f1_score(y_val.values, svc_prediction_result, average='macro'))\n",
    "\n",
    "print('confusion matrices: ')\n",
    "print(multilabel_confusion_matrix(y_val.values, svc_prediction_result))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_val.values, svc_prediction_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Support Vector Classification OneVsRestClassifier bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_bag_word_pipeline = Pipeline([('bagOfWord', CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 1))),\n",
    "                       ('nb_model', OneVsRestClassifier(LogisticRegression(C=10)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bagOfWord',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you...\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('nb_model',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight=None,\n",
       "                                                                  dual=False,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  intercept_scaling=1,\n",
       "                                                                  l1_ratio=None,\n",
       "                                                                  max_iter=100,\n",
       "                                                                  multi_class='auto',\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  penalty='l2',\n",
       "                                                                  random_state=None,\n",
       "                                                                  solver='lbfgs',\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  verbose=0,\n",
       "                                                                  warm_start=False),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_bag_word_pipeline.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_bag_word_prediction_result = logistic_regression_bag_word_pipeline.predict(X_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9644484958979034\n",
      "f1 Score weighted :  0.9640874691947594\n",
      "f1 Score micro :  0.9644484958979034\n",
      "f1 Score macro :  0.9326332887119126\n",
      "confusion matrices: \n",
      "[[[ 533    8]\n",
      "  [  10  546]]\n",
      "\n",
      " [[ 754   20]\n",
      "  [   4  319]]\n",
      "\n",
      " [[1041    2]\n",
      "  [   2   52]]\n",
      "\n",
      " [[1077    0]\n",
      "  [   2   18]]\n",
      "\n",
      " [[1088    0]\n",
      "  [   1    8]]\n",
      "\n",
      " [[1043    1]\n",
      "  [   9   44]]\n",
      "\n",
      " [[1054    5]\n",
      "  [   4   34]]\n",
      "\n",
      " [[1050    3]\n",
      "  [   7   37]]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.98       556\n",
      "           2       0.94      0.99      0.96       323\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       1.00      0.89      0.94         9\n",
      "           6       0.98      0.83      0.90        53\n",
      "           7       0.87      0.89      0.88        38\n",
      "           8       0.93      0.84      0.88        44\n",
      "\n",
      "    accuracy                           0.96      1097\n",
      "   macro avg       0.96      0.91      0.93      1097\n",
      "weighted avg       0.96      0.96      0.96      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy_score(y_val.values, logistic_regression_bag_word_prediction_result))\n",
    "print(\"f1 Score weighted : \",f1_score(y_val.values, logistic_regression_bag_word_prediction_result, average='weighted'))\n",
    "print(\"f1 Score micro : \",f1_score(y_val.values, logistic_regression_bag_word_prediction_result, average='micro'))\n",
    "print(\"f1 Score macro : \",f1_score(y_val.values, logistic_regression_bag_word_prediction_result, average='macro'))\n",
    "print('confusion matrices: ')\n",
    "print(multilabel_confusion_matrix(y_val.values, logistic_regression_bag_word_prediction_result))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_val.values, logistic_regression_bag_word_prediction_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation and Regression Lines - A Quick Recap #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"./HackerRankFile/CorrelationAndRegressionLines.png\" alt=\"Correlation And Regression Lines\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation and Regression Lines - A Quick Recap #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"./HackerRankFile/CorrelationAndRegressionLines.png\" alt=\"Correlation And Regression Lines\" style=\"height: 900px; width:900px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n",
      "0.92\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "input_data_all = \"\"\"73  72  76\n",
    "48  67  76\n",
    "95  92  95\n",
    "95  95  96\n",
    "33  59  79\n",
    "47  58  74\n",
    "98  95  97\n",
    "91  94  97\n",
    "95  84  90\n",
    "93  83  90\n",
    "70  70  78\n",
    "85  79  91\n",
    "33  67  76\n",
    "47  73  90\n",
    "95  87  95\n",
    "84  86  95\n",
    "43  63  75\n",
    "95  92  100\n",
    "54  80  87\n",
    "72  76  90\"\"\"\n",
    "input_data_all = input_data_all.split(\"\\n\")\n",
    "input_data_all\n",
    "\n",
    "M = []\n",
    "P = []\n",
    "C = []\n",
    "for one_element in input_data_all:\n",
    "    split_element = one_element.split(\" \")\n",
    "    M.append(int(split_element[0]))\n",
    "    P.append(int(split_element[2]))\n",
    "    C.append(int(split_element[4]))\n",
    "    \n",
    "    \n",
    "import math\n",
    "\n",
    "def mean_list(list_to_mean):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return sum(list_to_mean)/len(list_to_mean)\n",
    "\n",
    "def different_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]-second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "\n",
    "def product_between_two_vector(first_vector, second_vector):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result_diff = []\n",
    "    \n",
    "    for one_values in range(len(first_vector)):\n",
    "        result_diff.append(first_vector[one_values]*second_vector[one_values])\n",
    "    return result_diff\n",
    "\n",
    "    \n",
    "def compute_coef_regression(X, Y):\n",
    "    \"\"\"\n",
    "        Y = A+BX\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_x = mean_list(X)\n",
    "    mean_y = mean_list(Y)\n",
    "    \n",
    "    cov_X_Y = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(Y, len(Y)*[mean_y])))\n",
    "    var_X = sum(product_between_two_vector(different_between_two_vector(X, len(X)*[mean_x]), different_between_two_vector(X, len(X)*[mean_x])))\n",
    "    var_Y = sum(product_between_two_vector(different_between_two_vector(Y, len(Y)*[mean_y]), different_between_two_vector(Y, len(X)*[mean_y])))\n",
    "    return cov_X_Y/math.sqrt(var_X*var_Y)\n",
    "\n",
    "\n",
    "print('%.2f' % round(compute_coef_regression(M, P),2))\n",
    "print('%.2f' % round(compute_coef_regression(P, C),2))\n",
    "print('%.2f' % round(compute_coef_regression(M, C),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n",
      "0.92\n",
      "0.81\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = (9 * 7 + 107) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.5\n"
     ]
    }
   ],
   "source": [
    "print(round((107+9*7)/20,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.458333333333332"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
